{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHMu6EWGbv44",
        "outputId": "0bd8ae27-c9f5-4abe-d8fe-e4c6919b0891"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow>=2.13.0 transformers matplotlib seaborn scikit-learn\n",
        "\n",
        "# Connect to my google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# copy files from google drive to project\n",
        "!cp '/content/drive/MyDrive/Uni/BD/part-00000.snappy.parquet' '/content/'\n",
        "!cp '/content/drive/MyDrive/Uni/BD/part-00001.snappy.parquet' '/content/'\n",
        "!cp '/content/drive/MyDrive/Uni/BD/part-00002.snappy.parquet' '/content/'\n",
        "!cp '/content/drive/MyDrive/Uni/BD/part-00003.snappy.parquet' '/content/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY9cpuzI48_i"
      },
      "source": [
        "### Now"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n2XPjFl5eG4y",
        "outputId": "990316bd-ad70-4221-ee07-df593ee9a2cf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:PySpark not available. Will use pandas for data loading.\n",
            "WARNING:__main__:No accelerator detected, using CPU\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7363 - auc: 0.0000e+00 - loss: 0.5106\n",
            "Epoch 1: val_loss improved from inf to 0.05236, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7414 - auc: 0.0000e+00 - loss: 0.5045 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0524 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9992 - auc: 0.0000e+00 - loss: 0.0520\n",
            "Epoch 2: val_loss improved from 0.05236 to 0.04999, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9992 - auc: 0.0000e+00 - loss: 0.0515 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0500 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9999 - auc: 0.0000e+00 - loss: 0.0138\n",
            "Epoch 3: val_loss improved from 0.04999 to 0.03539, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9999 - auc: 0.0000e+00 - loss: 0.0137 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0354 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9999 - auc: 0.0000e+00 - loss: 0.0071\n",
            "Epoch 4: val_loss improved from 0.03539 to 0.01963, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9999 - auc: 0.0000e+00 - loss: 0.0071 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0196 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9999 - auc: 0.0000e+00 - loss: 0.0044\n",
            "Epoch 5: val_loss improved from 0.01963 to 0.01015, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9999 - auc: 0.0000e+00 - loss: 0.0044 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0102 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 5.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:__main__:No accelerator detected, using CPU\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8963 - auc: 0.5173 - loss: 0.3879\n",
            "Epoch 1: val_loss improved from inf to 0.21792, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8979 - auc: 0.5180 - loss: 0.3839 - val_accuracy: 0.9701 - val_auc: 0.4735 - val_loss: 0.2179 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9695 - auc: 0.6665 - loss: 0.1387\n",
            "Epoch 2: val_loss improved from 0.21792 to 0.19818, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.9695 - auc: 0.6682 - loss: 0.1384 - val_accuracy: 0.9701 - val_auc: 0.5352 - val_loss: 0.1982 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9701 - auc: 0.8127 - loss: 0.1136\n",
            "Epoch 3: val_loss improved from 0.19818 to 0.17331, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9701 - auc: 0.8132 - loss: 0.1135 - val_accuracy: 0.9701 - val_auc: 0.6190 - val_loss: 0.1733 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9715 - auc: 0.8696 - loss: 0.0996\n",
            "Epoch 4: val_loss improved from 0.17331 to 0.15166, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9715 - auc: 0.8699 - loss: 0.0996 - val_accuracy: 0.9705 - val_auc: 0.7047 - val_loss: 0.1517 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9723 - auc: 0.8978 - loss: 0.0914\n",
            "Epoch 5: val_loss improved from 0.15166 to 0.13632, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.9724 - auc: 0.8979 - loss: 0.0913 - val_accuracy: 0.9713 - val_auc: 0.7863 - val_loss: 0.1363 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 5.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:__main__:No accelerator detected, using CPU\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8850 - auc: 0.0000e+00 - loss: 0.4036\n",
            "Epoch 1: val_loss improved from inf to 0.04410, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 2s/step - accuracy: 0.8875 - auc: 0.0000e+00 - loss: 0.3980 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0441 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9995 - auc: 0.0000e+00 - loss: 0.0245\n",
            "Epoch 2: val_loss did not improve from 0.04410\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.9995 - auc: 0.0000e+00 - loss: 0.0242 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0603 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9999 - auc: 0.0000e+00 - loss: 0.0055\n",
            "Epoch 3: val_loss improved from 0.04410 to 0.04393, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 0.9999 - auc: 0.0000e+00 - loss: 0.0055 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0439 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0027\n",
            "Epoch 4: val_loss improved from 0.04393 to 0.02511, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0027 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0251 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0017\n",
            "Epoch 5: val_loss improved from 0.02511 to 0.01308, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0017 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0131 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 5.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:__main__:No accelerator detected, using CPU\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6789 - auc: 0.0000e+00 - loss: 0.5618\n",
            "Epoch 1: val_loss improved from inf to 0.17322, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 2s/step - accuracy: 0.6851 - auc: 0.0000e+00 - loss: 0.5551 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.1732 - learning_rate: 0.0010\n",
            "Epoch 2/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9966 - auc: 0.0000e+00 - loss: 0.0992\n",
            "Epoch 2: val_loss improved from 0.17322 to 0.09303, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.9967 - auc: 0.0000e+00 - loss: 0.0981 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0930 - learning_rate: 0.0010\n",
            "Epoch 3/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9995 - auc: 0.0000e+00 - loss: 0.0233\n",
            "Epoch 3: val_loss improved from 0.09303 to 0.07109, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.9995 - auc: 0.0000e+00 - loss: 0.0232 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0711 - learning_rate: 0.0010\n",
            "Epoch 4/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.9999 - auc: 0.0000e+00 - loss: 0.0099\n",
            "Epoch 4: val_loss improved from 0.07109 to 0.04289, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 0.9999 - auc: 0.0000e+00 - loss: 0.0099 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0429 - learning_rate: 0.0010\n",
            "Epoch 5/5\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0057\n",
            "Epoch 5: val_loss improved from 0.04289 to 0.02277, saving model to /content/best_LSTM_pipeline_model.h5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 2s/step - accuracy: 1.0000 - auc: 0.0000e+00 - loss: 0.0057 - val_accuracy: 1.0000 - val_auc: 0.0000e+00 - val_loss: 0.0228 - learning_rate: 0.0010\n",
            "Restoring model weights from the end of the best epoch: 5.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Deep Learning Models for Sentiment Analysis - GPU/TPU Optimized for Google Colab\n",
        "PIPELINE-COMPATIBLE VERSION - Works with existing MICAP preprocessing pipeline\n",
        "Implements LSTM, CNN, and Transformer models with CUDA/TPU acceleration\n",
        "\n",
        "Dependencies: tensorflow>=2.13.0, pandas, numpy, pyspark (for data loading)\n",
        "Environment: Google Colab with GPU/TPU runtime\n",
        "Pipeline: Reads from preprocessed parquet files created by MICAP pipeline\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import logging\n",
        "import time\n",
        "from typing import Dict, List, Tuple, Optional, Union\n",
        "import json\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "\n",
        "# TensorFlow imports with GPU optimization\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, callbacks, optimizers\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.mixed_precision import LossScaleOptimizer\n",
        "\n",
        "# Additional ML libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# PySpark imports for reading existing pipeline data\n",
        "try:\n",
        "    from pyspark.sql import SparkSession\n",
        "    from pyspark.sql.functions import col\n",
        "    PYSPARK_AVAILABLE = True\n",
        "except ImportError:\n",
        "    PYSPARK_AVAILABLE = False\n",
        "    logging.warning(\"PySpark not available. Will use pandas for data loading.\")\n",
        "\n",
        "tf.config.optimizer.set_jit(True)      # XLA compilation\n",
        "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
        "\n",
        "# Configure warnings and logging\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[logging.StreamHandler()]\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class PipelineDataLoader:\n",
        "    \"\"\"\n",
        "    Loads data from MICAP preprocessing pipeline (parquet files)\n",
        "    Maintains compatibility with existing feature engineering\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Initialize pipeline data loader.\"\"\"\n",
        "        self.spark = None\n",
        "        if PYSPARK_AVAILABLE:\n",
        "            self._init_spark_session()\n",
        "\n",
        "    def _init_spark_session(self):\n",
        "        \"\"\"Initialize Spark session for reading parquet files.\"\"\"\n",
        "        try:\n",
        "            self.spark = (SparkSession.builder\n",
        "                         .appName(\"ColabDataLoader\")\n",
        "                         .master(\"local[*]\")\n",
        "                         .config(\"spark.driver.memory\", \"64g\")\n",
        "                         .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
        "                         .getOrCreate())\n",
        "            self.spark.sparkContext.setLogLevel(\"WARN\")\n",
        "            logger.info(\"Spark session created for pipeline data loading\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to create Spark session: {e}\")\n",
        "            self.spark = None\n",
        "\n",
        "    def load_pipeline_data(self, data_path: str,\n",
        "                          sample_fraction: float = 1.0,\n",
        "                          use_spark: bool = True) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Load preprocessed data from MICAP pipeline.\n",
        "\n",
        "        Args:\n",
        "            data_path: Path to processed parquet file or directory\n",
        "            sample_fraction: Fraction of data to use\n",
        "            use_spark: Whether to use Spark for loading (fallback to pandas)\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: Loaded and sampled data\n",
        "        \"\"\"\n",
        "        logger.info(f\"Loading pipeline data from: {data_path}\")\n",
        "\n",
        "        if use_spark and self.spark and PYSPARK_AVAILABLE:\n",
        "            return self._load_with_spark(data_path, sample_fraction)\n",
        "        else:\n",
        "            return self._load_with_pandas(data_path, sample_fraction)\n",
        "\n",
        "    def _load_with_spark(self, data_path: str, sample_fraction: float) -> pd.DataFrame:\n",
        "        \"\"\"Load data using Spark (maintains original pipeline compatibility).\"\"\"\n",
        "        logger.info(\"Loading data with Spark...\")\n",
        "\n",
        "        try:\n",
        "            # Read parquet file(s)\n",
        "            df = self.spark.read.parquet(data_path)\n",
        "\n",
        "            # Sample if requested\n",
        "            if sample_fraction < 1.0:\n",
        "                df = df.sample(sample_fraction, seed=42)\n",
        "\n",
        "            # Convert to pandas for TensorFlow compatibility\n",
        "            # Use efficient streaming for large datasets\n",
        "            pandas_df = self._spark_to_pandas_efficient(df)\n",
        "\n",
        "            logger.info(f\"Loaded {len(pandas_df)} records with Spark\")\n",
        "            return pandas_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Spark loading failed: {e}\")\n",
        "            logger.info(\"Falling back to pandas...\")\n",
        "            return self._load_with_pandas(data_path, sample_fraction)\n",
        "\n",
        "    def _load_with_pandas(self, data_path: str, sample_fraction: float) -> pd.DataFrame:\n",
        "        \"\"\"Load data with pandas (fallback method).\"\"\"\n",
        "        logger.info(\"Loading data with pandas...\")\n",
        "\n",
        "        try:\n",
        "            # Try reading as parquet first\n",
        "            if data_path.endswith('.parquet') or os.path.isdir(data_path):\n",
        "                df = pd.read_parquet(data_path)\n",
        "            else:\n",
        "                # Fallback to CSV\n",
        "                df = pd.read_csv(data_path)\n",
        "\n",
        "            # Sample if requested\n",
        "            if sample_fraction < 1.0:\n",
        "                df = df.sample(frac=sample_fraction, random_state=42)\n",
        "\n",
        "            logger.info(f\"Loaded {len(df)} records with pandas\")\n",
        "            return df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to load data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def _spark_to_pandas_efficient(self, spark_df, batch_size: int = 50000) -> pd.DataFrame:\n",
        "        \"\"\"Efficiently convert Spark DataFrame to pandas using streaming.\"\"\"\n",
        "        try:\n",
        "            # Try direct conversion for smaller datasets\n",
        "            if spark_df.count() < batch_size:\n",
        "                return spark_df.toPandas()\n",
        "\n",
        "            # Stream large datasets in batches\n",
        "            logger.info(\"Streaming large dataset in batches...\")\n",
        "            parts = []\n",
        "            for batch in spark_df.toLocalIterator(batch_size):\n",
        "                batch_df = pd.DataFrame(list(batch), columns=spark_df.columns)\n",
        "                parts.append(batch_df)\n",
        "\n",
        "            return pd.concat(parts, ignore_index=True)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Streaming failed, using direct conversion: {e}\")\n",
        "            return spark_df.toPandas()\n",
        "\n",
        "    def validate_pipeline_features(self, df: pd.DataFrame) -> bool:\n",
        "        \"\"\"\n",
        "        Validate that the DataFrame contains expected pipeline features.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame to validate\n",
        "\n",
        "        Returns:\n",
        "            bool: True if valid pipeline data\n",
        "        \"\"\"\n",
        "        # Expected features from MICAP pipeline\n",
        "        required_features = [\n",
        "            'text', 'sentiment', 'text_processed',\n",
        "            'text_length', 'processed_length', 'token_count'\n",
        "        ]\n",
        "\n",
        "        # Optional but expected features\n",
        "        expected_features = [\n",
        "            'vader_compound', 'vader_positive', 'vader_negative', 'vader_neutral',\n",
        "            'emoji_sentiment', 'exclamation_count', 'question_count',\n",
        "            'uppercase_ratio', 'punctuation_density',\n",
        "            'hour_sin', 'hour_cos', 'is_weekend'\n",
        "        ]\n",
        "\n",
        "        # Check required features\n",
        "        missing_required = [f for f in required_features if f not in df.columns]\n",
        "        if missing_required:\n",
        "            logger.error(f\"Missing required pipeline features: {missing_required}\")\n",
        "            return False\n",
        "\n",
        "        # Log available optional features\n",
        "        available_optional = [f for f in expected_features if f in df.columns]\n",
        "        logger.info(f\"Available pipeline features: {len(available_optional)}/{len(expected_features)}\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def prepare_features_for_training(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, Dict]:\n",
        "        \"\"\"\n",
        "        Prepare features from pipeline data for deep learning training.\n",
        "\n",
        "        Args:\n",
        "            df: DataFrame with pipeline features\n",
        "\n",
        "        Returns:\n",
        "            Tuple of (text_sequences, labels, feature_info)\n",
        "        \"\"\"\n",
        "        logger.info(\"Preparing pipeline features for training...\")\n",
        "\n",
        "        # Validate data\n",
        "        if not self.validate_pipeline_features(df):\n",
        "            raise ValueError(\"Invalid pipeline data structure\")\n",
        "\n",
        "        # Use processed text for deep learning (already cleaned by pipeline)\n",
        "        text_column = 'text_processed' if 'text_processed' in df.columns else 'text'\n",
        "        texts = df[text_column].fillna('').astype(str)\n",
        "        labels = df['sentiment'].values\n",
        "\n",
        "        # Extract numeric features created by pipeline\n",
        "        numeric_features = []\n",
        "        feature_names = []\n",
        "\n",
        "        # Basic text features\n",
        "        if 'text_length' in df.columns:\n",
        "            numeric_features.append(df['text_length'].fillna(0))\n",
        "            feature_names.append('text_length')\n",
        "\n",
        "        if 'token_count' in df.columns:\n",
        "            numeric_features.append(df['token_count'].fillna(0))\n",
        "            feature_names.append('token_count')\n",
        "\n",
        "        # VADER sentiment features\n",
        "        vader_features = ['vader_compound', 'vader_positive', 'vader_negative', 'vader_neutral']\n",
        "        for feature in vader_features:\n",
        "            if feature in df.columns:\n",
        "                numeric_features.append(df[feature].fillna(0))\n",
        "                feature_names.append(feature)\n",
        "\n",
        "        # Emoji and text statistics\n",
        "        text_stat_features = ['emoji_sentiment', 'exclamation_count', 'question_count',\n",
        "                             'uppercase_ratio', 'punctuation_density']\n",
        "        for feature in text_stat_features:\n",
        "            if feature in df.columns:\n",
        "                numeric_features.append(df[feature].fillna(0))\n",
        "                feature_names.append(feature)\n",
        "\n",
        "        # Temporal features\n",
        "        temporal_features = ['hour_sin', 'hour_cos', 'is_weekend']\n",
        "        for feature in temporal_features:\n",
        "            if feature in df.columns:\n",
        "                numeric_features.append(df[feature].fillna(0))\n",
        "                feature_names.append(feature)\n",
        "\n",
        "        # Combine numeric features\n",
        "        if numeric_features:\n",
        "            numeric_array = np.column_stack(numeric_features)\n",
        "            logger.info(f\"Extracted {len(feature_names)} numeric features: {feature_names}\")\n",
        "        else:\n",
        "            numeric_array = None\n",
        "            logger.warning(\"No numeric features found in pipeline data\")\n",
        "\n",
        "        feature_info = {\n",
        "            'text_column': text_column,\n",
        "            'numeric_features': feature_names,\n",
        "            'numeric_shape': numeric_array.shape if numeric_array is not None else None,\n",
        "            'text_samples': len(texts),\n",
        "            'label_distribution': pd.Series(labels).value_counts().to_dict()\n",
        "        }\n",
        "\n",
        "        logger.info(f\"Feature preparation completed: {feature_info}\")\n",
        "\n",
        "        return texts.values, labels, numeric_array, feature_info\n",
        "\n",
        "\n",
        "class GPUEnvironmentManager:\n",
        "    \"\"\"Manages GPU/TPU environment setup and optimization for Google Colab\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device_type = self._detect_accelerator()\n",
        "        self.strategy = self._setup_distribution_strategy()\n",
        "        self.mixed_precision_enabled = False\n",
        "        # self._configure_mixed_precision()\n",
        "        self._log_environment_info()\n",
        "\n",
        "        # if self.device_type == 'GPU':\n",
        "            # self._setup_mixed_precision()\n",
        "\n",
        "    def _detect_accelerator(self) -> str:\n",
        "        \"\"\"Detect available accelerator (GPU/TPU/CPU)\"\"\"\n",
        "        try:\n",
        "            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "            tf.config.experimental_connect_to_cluster(tpu)\n",
        "            tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "            logger.info(\"TPU detected and initialized\")\n",
        "            return 'TPU'\n",
        "        except (ValueError, RuntimeError):\n",
        "            pass\n",
        "\n",
        "        gpus = tf.config.list_physical_devices('GPU')\n",
        "        if gpus:\n",
        "            logger.info(f\"GPU detected: {len(gpus)} device(s)\")\n",
        "            for gpu in gpus:\n",
        "                tf.config.experimental.set_memory_growth(gpu, True)\n",
        "            return 'GPU'\n",
        "\n",
        "        logger.warning(\"No accelerator detected, using CPU\")\n",
        "        return 'CPU'\n",
        "\n",
        "    def _setup_distribution_strategy(self):\n",
        "        \"\"\"Setup distribution strategy based on hardware\"\"\"\n",
        "        if self.device_type == 'TPU':\n",
        "            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "            strategy = tf.distribute.TPUStrategy(tpu)\n",
        "            logger.info(f\"Using TPU strategy with {strategy.num_replicas_in_sync} replicas\")\n",
        "        elif self.device_type == 'GPU':\n",
        "            strategy = tf.distribute.MirroredStrategy()\n",
        "            logger.info(f\"Using MirroredStrategy with {strategy.num_replicas_in_sync} replicas\")\n",
        "        else:\n",
        "            strategy = tf.distribute.get_strategy()\n",
        "            logger.info(\"Using default strategy (CPU)\")\n",
        "\n",
        "        return strategy\n",
        "\n",
        "    def _setup_mixed_precision(self):\n",
        "        \"\"\"Setup mixed precision training for faster GPU training\"\"\"\n",
        "        try:\n",
        "            policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "            tf.keras.mixed_precision.set_global_policy(policy)\n",
        "            self.mixed_precision_enabled = True\n",
        "            logger.info(\"Mixed precision training enabled (float16)\")\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Could not enable mixed precision: {e}\")\n",
        "\n",
        "    def _log_environment_info(self):\n",
        "        \"\"\"Log environment information\"\"\"\n",
        "        logger.info(\"=== GPU/TPU Environment Information ===\")\n",
        "        logger.info(f\"TensorFlow version: {tf.__version__}\")\n",
        "        logger.info(f\"Detected accelerator: {self.device_type}\")\n",
        "\n",
        "        if self.device_type == 'GPU':\n",
        "            gpus = tf.config.list_physical_devices('GPU')\n",
        "            for i, gpu in enumerate(gpus):\n",
        "                logger.info(f\"GPU {i}: {gpu}\")\n",
        "\n",
        "        logger.info(\"=\" * 50)\n",
        "\n",
        "    def get_optimal_batch_size(self, base_batch_size: int = 16384) -> int:\n",
        "        \"\"\"Calculate optimal batch size based on hardware\"\"\"\n",
        "        if self.device_type == 'TPU':\n",
        "            return max(128, base_batch_size * 8)\n",
        "        elif self.device_type == 'GPU':\n",
        "            return base_batch_size * max(1, self.strategy.num_replicas_in_sync)\n",
        "        else:\n",
        "            return max(16, base_batch_size // 2)\n",
        "\n",
        "\n",
        "class PipelineOptimizedModel:\n",
        "    \"\"\"\n",
        "    Base class for pipeline-compatible GPU/TPU optimized deep learning models\n",
        "    Works with features from MICAP preprocessing pipeline\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, env_manager: GPUEnvironmentManager,\n",
        "                 max_words: int = 10000, max_length: int = 100):\n",
        "        self.env_manager = env_manager\n",
        "        self.max_words = max_words\n",
        "        self.max_length = max_length\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "        self.history = None\n",
        "        self.training_time = 0\n",
        "        self.numeric_features_dim = 0\n",
        "\n",
        "    def prepare_data(self, texts: np.ndarray, labels: np.ndarray,\n",
        "                    numeric_features: Optional[np.ndarray] = None,\n",
        "                    validation_split: float = 0.2) -> Tuple:\n",
        "        \"\"\"\n",
        "        Prepare text and numeric features for training.\n",
        "\n",
        "        Args:\n",
        "            texts: Array of text data\n",
        "            labels: Array of labels\n",
        "            numeric_features: Optional array of numeric features from pipeline\n",
        "            validation_split: Validation split ratio\n",
        "\n",
        "        Returns:\n",
        "            Tuple of prepared datasets\n",
        "        \"\"\"\n",
        "        logger.info(\"Preparing data for pipeline-compatible training...\")\n",
        "\n",
        "        # Initialize tokenizer\n",
        "        self.tokenizer = Tokenizer(\n",
        "            num_words=self.max_words,\n",
        "            oov_token='<OOV>',\n",
        "            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "        )\n",
        "\n",
        "        # Fit tokenizer\n",
        "        self.tokenizer.fit_on_texts(texts)\n",
        "\n",
        "        # Convert to sequences\n",
        "        sequences = self.tokenizer.texts_to_sequences(texts)\n",
        "        X_text = pad_sequences(sequences, maxlen=self.max_length,\n",
        "                              padding='post', truncating='post')\n",
        "\n",
        "        # Prepare numeric features if available\n",
        "        X_numeric = None\n",
        "        if numeric_features is not None:\n",
        "            X_numeric = numeric_features.astype(np.float32)\n",
        "            self.numeric_features_dim = X_numeric.shape[1]\n",
        "            logger.info(f\"Using {self.numeric_features_dim} numeric features from pipeline\")\n",
        "\n",
        "        y = labels.astype(np.float32)\n",
        "\n",
        "        # Split data\n",
        "        if X_numeric is not None:\n",
        "            X_text_train, X_text_val, X_num_train, X_num_val, y_train, y_val = train_test_split(\n",
        "                X_text, X_numeric, y, test_size=validation_split,\n",
        "                random_state=42, stratify=y\n",
        "            )\n",
        "\n",
        "            return (X_text_train, X_num_train, y_train), (X_text_val, X_num_val, y_val)\n",
        "        else:\n",
        "            X_text_train, X_text_val, y_train, y_val = train_test_split(\n",
        "                X_text, y, test_size=validation_split,\n",
        "                random_state=42, stratify=y\n",
        "            )\n",
        "\n",
        "            return (X_text_train, y_train), (X_text_val, y_val)\n",
        "\n",
        "    def _get_optimizer(self, learning_rate: float = 0.001):\n",
        "        \"\"\"Get optimized optimizer\"\"\"\n",
        "        if self.env_manager.device_type == 'TPU':\n",
        "            optimizer = optimizers.Adam(learning_rate=learning_rate * 2)\n",
        "        else:\n",
        "            optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "        if self.env_manager.mixed_precision_enabled:\n",
        "            optimizer = LossScaleOptimizer(optimizer)\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    def _get_callbacks(self, model_name: str, patience: int = 5):\n",
        "        \"\"\"Get training callbacks\"\"\"\n",
        "        return [\n",
        "            callbacks.EarlyStopping(\n",
        "                monitor='val_loss', patience=patience,\n",
        "                restore_best_weights=True, verbose=1\n",
        "            ),\n",
        "            callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_loss', factor=0.5,\n",
        "                patience=max(2, patience // 2), min_lr=1e-7, verbose=1\n",
        "            ),\n",
        "            callbacks.ModelCheckpoint(\n",
        "                filepath=f'/content/best_{model_name}_pipeline_model.h5',\n",
        "                monitor='val_loss', save_best_only=True, verbose=1\n",
        "            )\n",
        "        ]\n",
        "\n",
        "\n",
        "class PipelineLSTMModel(PipelineOptimizedModel):\n",
        "    \"\"\"LSTM model optimized for pipeline features\"\"\"\n",
        "\n",
        "    def build_model(self, embedding_dim: int = 128, lstm_units: int = 64,\n",
        "                   dropout_rate: float = 0.3):\n",
        "        \"\"\"Build LSTM model with optional numeric features integration\"\"\"\n",
        "        logger.info(\"Building pipeline-compatible LSTM model...\")\n",
        "\n",
        "        with self.env_manager.strategy.scope():\n",
        "            # Text input branch\n",
        "            text_input = layers.Input(shape=(self.max_length,), name='text_input')\n",
        "\n",
        "            # Embedding layer\n",
        "            embedding = layers.Embedding(\n",
        "                input_dim=self.max_words,\n",
        "                output_dim=embedding_dim,\n",
        "                input_length=self.max_length,\n",
        "                mask_zero=True,\n",
        "                name='embedding'\n",
        "            )(text_input)\n",
        "\n",
        "            embedding = layers.SpatialDropout1D(dropout_rate * 0.5)(embedding)\n",
        "\n",
        "            # Bidirectional LSTM layers\n",
        "            lstm1 = layers.Bidirectional(\n",
        "                layers.LSTM(lstm_units, dropout=dropout_rate,\n",
        "                            return_sequences=True),\n",
        "                name='bi_lstm_1'\n",
        "            )(embedding)\n",
        "\n",
        "            lstm2 = layers.Bidirectional(\n",
        "                layers.LSTM(lstm_units // 2, dropout=dropout_rate,\n",
        "                            return_sequences=False),\n",
        "                name='bi_lstm_2'\n",
        "            )(lstm1)\n",
        "\n",
        "            # Text features\n",
        "            text_features = layers.Dense(64, activation='relu', name='text_dense')(lstm2)\n",
        "            text_features = layers.BatchNormalization()(text_features)\n",
        "            text_features = layers.Dropout(dropout_rate)(text_features)\n",
        "\n",
        "            # Combine with numeric features if available\n",
        "            if self.numeric_features_dim > 0:\n",
        "                # Numeric input branch\n",
        "                numeric_input = layers.Input(shape=(self.numeric_features_dim,), name='numeric_input')\n",
        "                numeric_features = layers.Dense(32, activation='relu', name='numeric_dense')(numeric_input)\n",
        "                numeric_features = layers.BatchNormalization()(numeric_features)\n",
        "                numeric_features = layers.Dropout(dropout_rate * 0.5)(numeric_features)\n",
        "\n",
        "                # Combine text and numeric features\n",
        "                combined = layers.Concatenate(name='combine_features')([text_features, numeric_features])\n",
        "                inputs = [text_input, numeric_input]\n",
        "            else:\n",
        "                combined = text_features\n",
        "                inputs = text_input\n",
        "\n",
        "            # Final classification layers\n",
        "            dense = layers.Dense(32, activation='relu', name='final_dense')(combined)\n",
        "            dense = layers.Dropout(dropout_rate * 0.5)(dense)\n",
        "\n",
        "            output = layers.Dense(1, activation='sigmoid', name='output')(dense)\n",
        "\n",
        "            model = models.Model(inputs=inputs, outputs=output, name='PipelineLSTM')\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "        # Compile model\n",
        "        optimizer = self._get_optimizer()\n",
        "        self.model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
        "        )\n",
        "\n",
        "        logger.info(\"LSTM Model Architecture:\")\n",
        "        self.model.summary(print_fn=logger.info)\n",
        "\n",
        "        return model\n",
        "\n",
        "    def train(self, train_data: Tuple, val_data: Tuple, epochs: int = 10):\n",
        "        \"\"\"Train the LSTM model\"\"\"\n",
        "        logger.info(\"Training pipeline LSTM model...\")\n",
        "\n",
        "        callbacks_list = self._get_callbacks('LSTM')\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Prepare training data\n",
        "        if self.numeric_features_dim > 0:\n",
        "            X_text_train, X_num_train, y_train = train_data\n",
        "            X_text_val, X_num_val, y_val = val_data\n",
        "\n",
        "            train_inputs = [X_text_train, X_num_train]\n",
        "            val_inputs = [X_text_val, X_num_val]\n",
        "        else:\n",
        "            X_text_train, y_train = train_data\n",
        "            X_text_val, y_val = val_data\n",
        "\n",
        "            train_inputs = X_text_train\n",
        "            val_inputs = X_text_val\n",
        "\n",
        "        batch_size = self.env_manager.get_optimal_batch_size()\n",
        "\n",
        "        # with self.env_manager.strategy.scope():\n",
        "        #     self.history = self.model.fit(\n",
        "        #         train_inputs, y_train,\n",
        "        #         batch_size=batch_size,\n",
        "        #         epochs=epochs,\n",
        "        #         validation_data=(val_inputs, y_val),\n",
        "        #         callbacks=callbacks_list,\n",
        "        #         verbose=1\n",
        "        #     )\n",
        "        def make_ds(x_text, x_num, y, shuffle=True):\n",
        "            inputs = (x_text, x_num) if x_num is not None else x_text\n",
        "            ds = tf.data.Dataset.from_tensor_slices((inputs, y))\n",
        "            if shuffle:\n",
        "                ds = ds.shuffle(100_000)\n",
        "            return ds.batch(batch_size, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "        train_ds = make_ds(*train_data, shuffle=True)\n",
        "        val_ds   = make_ds(*val_data,   shuffle=False)\n",
        "\n",
        "        with self.env_manager.strategy.scope():\n",
        "            self.history = self.model.fit(\n",
        "                train_ds,\n",
        "                epochs=epochs,\n",
        "                validation_data=val_ds,\n",
        "                callbacks=callbacks_list,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "        self.training_time = time.time() - start_time\n",
        "        logger.info(f\"Training completed in {self.training_time:.2f} seconds\")\n",
        "\n",
        "        return self.history.history\n",
        "\n",
        "\n",
        "def evaluate_pipeline_models_gpu(data_path: str,\n",
        "                                sample_fraction: float = 1.0,\n",
        "                                epochs: int = 10) -> Dict:\n",
        "    \"\"\"\n",
        "    Evaluate models using MICAP pipeline data with GPU/TPU optimization.\n",
        "\n",
        "    Args:\n",
        "        data_path: Path to processed pipeline data (parquet)\n",
        "        sample_fraction: Fraction of data to use\n",
        "        epochs: Number of training epochs\n",
        "\n",
        "    Returns:\n",
        "        Dict: Evaluation results\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting pipeline-compatible GPU evaluation...\")\n",
        "\n",
        "    # Initialize components\n",
        "    env_manager = GPUEnvironmentManager()\n",
        "    data_loader = PipelineDataLoader()\n",
        "\n",
        "    # Load pipeline data\n",
        "    df = data_loader.load_pipeline_data(data_path, sample_fraction)\n",
        "\n",
        "    # Prepare features\n",
        "    texts, labels, numeric_features, feature_info = data_loader.prepare_features_for_training(df)\n",
        "\n",
        "    logger.info(f\"Loaded pipeline data: {feature_info}\")\n",
        "\n",
        "    # Initialize models\n",
        "    models_to_evaluate = [\n",
        "        ('Pipeline_LSTM', PipelineLSTMModel)\n",
        "    ]\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    for model_name, ModelClass in models_to_evaluate:\n",
        "        logger.info(f\"\\n{'='*60}\")\n",
        "        logger.info(f\"Training {model_name}\")\n",
        "        logger.info(f\"{'='*60}\")\n",
        "\n",
        "        try:\n",
        "            # Initialize model\n",
        "            model = ModelClass(env_manager)\n",
        "\n",
        "            # Prepare data\n",
        "            train_data, val_data = model.prepare_data(\n",
        "                texts, labels, numeric_features\n",
        "            )\n",
        "\n",
        "            # Build model\n",
        "            model.build_model()\n",
        "\n",
        "            # Train model\n",
        "            history = model.train(train_data, val_data, epochs=epochs)\n",
        "\n",
        "            # Evaluate\n",
        "            if model.numeric_features_dim > 0:\n",
        "                val_inputs = [val_data[0], val_data[1]]\n",
        "                val_labels = val_data[2]\n",
        "            else:\n",
        "                val_inputs = val_data[0]\n",
        "                val_labels = val_data[1]\n",
        "\n",
        "            eval_results = model.model.evaluate(val_inputs, val_labels, verbose=0)\n",
        "\n",
        "            metrics = {}\n",
        "            for i, metric_name in enumerate(model.model.metrics_names):\n",
        "                metrics[metric_name] = eval_results[i]\n",
        "            metrics['training_time'] = model.training_time\n",
        "\n",
        "            results[model_name] = {\n",
        "                'metrics': metrics,\n",
        "                'history': history,\n",
        "                'feature_info': feature_info\n",
        "            }\n",
        "\n",
        "            # Save model\n",
        "            model.model.save(f'/content/{model_name.lower()}_model.h5')\n",
        "            logger.info(f\"Model saved as {model_name.lower()}_model.h5\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Failed to train {model_name}: {e}\")\n",
        "            results[model_name] = {'error': str(e)}\n",
        "\n",
        "    # Save results\n",
        "    with open('pipeline_model_results.json', 'w') as f:\n",
        "        json.dump(results, f, indent=2, default=str)\n",
        "\n",
        "    logger.info(\"Pipeline evaluation completed!\")\n",
        "    return results\n",
        "\n",
        "\n",
        "# Usage examples for Google Colab\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    Example usage in Google Colab:\n",
        "\n",
        "    # Option 1: Use your existing pipeline data (RECOMMENDED)\n",
        "    results = evaluate_pipeline_models_gpu(\n",
        "        data_path='/content/pipeline_features.parquet',  # Upload your processed parquet file\n",
        "        sample_fraction=1.0,\n",
        "        epochs=10\n",
        "    )\n",
        "\n",
        "    # Option 2: If you have PySpark setup in Colab (advanced)\n",
        "    # First run your preprocessing pipeline to create the parquet file\n",
        "    # Then use the above approach\n",
        "    \"\"\"\n",
        "\n",
        "    results = evaluate_pipeline_models_gpu(\n",
        "        'part-00000.snappy.parquet',\n",
        "        sample_fraction=1.0,\n",
        "        epochs=5\n",
        "    )\n",
        "    results = evaluate_pipeline_models_gpu(\n",
        "        'part-00001.snappy.parquet',\n",
        "        sample_fraction=1.0,\n",
        "        epochs=5\n",
        "    )\n",
        "    results = evaluate_pipeline_models_gpu(\n",
        "        'part-00002.snappy.parquet',\n",
        "        sample_fraction=1.0,\n",
        "        epochs=5\n",
        "    )\n",
        "    results = evaluate_pipeline_models_gpu(\n",
        "        'part-00003.snappy.parquet',\n",
        "        sample_fraction=1.0,\n",
        "        epochs=5\n",
        "    )\n",
        "\n",
        "    logger.info(\"Pipeline-compatible GPU deep learning models ready!\")\n",
        "    logger.info(\"Upload your 'pipeline_features.parquet' file to /content/ and run evaluation.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V6E1",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
