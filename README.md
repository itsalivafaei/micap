# MICAP - Market Intelligence & Competitor Analysis Platform

[![CI/CD Pipeline](https://github.com/itsalivafaei/micap/workflows/MICAP%20CI/CD%20Pipeline/badge.svg)](https://github.com/itsalivafaei/micap/actions)
[![Documentation](https://github.com/itsalivafaei/micap/workflows/Documentation%20CI/badge.svg)](https://github.com/itsalivafaei/micap/actions)
[![Code Coverage](https://codecov.io/gh/itsalivafaei/micap/branch/main/graph/badge.svg)](https://codecov.io/gh/itsalivafaei/micap)
[![Python 3.11](https://img.shields.io/badge/python-3.11-blue.svg)](https://www.python.org/downloads/release/python-3110/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Model Accuracy](https://img.shields.io/badge/LSTM%20Accuracy-75.4%25-green.svg)](https://github.com/itsalivafaei/micap#results--achievements)
[![Data Processed](https://img.shields.io/badge/Records%20Processed-1.16M+-blue.svg)](https://github.com/itsalivafaei/micap#results--achievements)
[![Performance](https://img.shields.io/badge/Processing%20Speed-1.8K%20rec%2Fsec-orange.svg)](https://github.com/itsalivafaei/micap#results--achievements)

A comprehensive machine learning platform for market intelligence and competitor analysis using distributed computing with Apache Spark, advanced NLP, and deep learning models.

## üöÄ Features

- **Distributed Processing**: Scalable data processing with Apache Spark
- **Advanced NLP**: Multi-model sentiment analysis (VADER, TextBlob, BERT, custom models)
- **Deep Learning**: LSTM, CNN, and Transformer models for sentiment classification
- **Real-time Analytics**: Temporal trend analysis and anomaly detection
- **Competitor Analysis**: Brand recognition and competitive intelligence
- **MLOps Ready**: Integrated with MLflow for model tracking and deployment
- **Modern Architecture**: FastAPI backend, containerized deployment, monitoring

## üìã Table of Contents

- [Features](#-features)
- [Quick Start](#-quick-start)
- [Installation](#-installation)
- [Usage](#-usage)
- [Architecture](#-architecture)
- [Results & Achievements](#-results--achievements)
- [API Documentation](#-api-documentation)
- [Development](#-development)
- [Testing](#-testing)
- [Deployment](#-deployment)
- [Contributing](#-contributing)
- [License](#-license)

## ‚ö° Quick Start

### Using Docker Compose (Recommended)

```bash
# Clone the repository
git clone https://github.com/itsalivafaei/micap.git
cd micap

# Start the complete stack
docker-compose up -d

# Access the applications
# - API: http://localhost:8000
# - Spark UI: http://localhost:8080
# - Jupyter: http://localhost:8888
# - Grafana: http://localhost:3000
```

### Local Development

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
pip install -r requirements-dev.txt

# Download required models
python -m spacy download en_core_web_sm

# Run the pipeline
python scripts/run_phase1_pipeline.py
```

## üõ† Installation

### Prerequisites

- Python 3.11+
- Java 11+ (for Spark)
- Docker & Docker Compose (optional)
- 8GB+ RAM recommended

### System Dependencies

**macOS:**
```bash
brew install openjdk@11 python@3.11
```

**Ubuntu:**
```bash
sudo apt-get update
sudo apt-get install openjdk-11-jdk python3.11 python3.11-venv
```

### Python Environment

```bash
# Clone repository
git clone https://github.com/itsalivafaei/micap.git
cd micap

# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate

# Install package in development mode
pip install -e .

# Install development dependencies
pip install -r requirements-dev.txt

# Setup pre-commit hooks
pre-commit install
```

## üìñ Usage

### Basic Pipeline Execution

```python
from src.spark.preprocessing import TextPreprocessor
from src.ml.sentiment_models import ModelEvaluator
from config.spark_config import create_spark_session

# Initialize Spark session
spark = create_spark_session("MICAP-Analysis")

# Load and preprocess data
preprocessor = TextPreprocessor(spark)
df = preprocessor.load_and_preprocess("data/raw/tweets.csv")

# Train and evaluate models
evaluator = ModelEvaluator(spark)
results = evaluator.evaluate_all_models(train_df, test_df, feature_cols)
```

### API Usage

```python
import requests

# Analyze sentiment
response = requests.post("http://localhost:8000/analyze", 
                        json={"text": "Great product! Love it!"})
print(response.json())

# Get trend analysis
response = requests.get("http://localhost:8000/trends/sentiment")
print(response.json())
```

### Running Specific Components

```bash
# Train all models
python scripts/train_all_models.py

# Run competitor analysis
python src/spark/competitor_analysis.py

# Performance benchmarking
python scripts/benchmark_performance.py

# Start API server
uvicorn src.api.main:app --reload
```

## üèó Architecture

```
MICAP/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ spark/              # Distributed data processing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ temporal_analysis.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ competitor_analysis.py
‚îÇ   ‚îú‚îÄ‚îÄ ml/                 # Machine learning models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sentiment_models.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ deep_learning_models.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ entity_recognition.py
‚îÇ   ‚îú‚îÄ‚îÄ api/                # FastAPI backend
‚îÇ   ‚îî‚îÄ‚îÄ utils/              # Shared utilities
‚îú‚îÄ‚îÄ scripts/                # Pipeline execution scripts
‚îú‚îÄ‚îÄ tests/                  # Comprehensive test suite
‚îú‚îÄ‚îÄ config/                 # Configuration files
‚îî‚îÄ‚îÄ data/                   # Data storage
```

### Key Components

- **Data Ingestion**: Scalable data loading and validation
- **Preprocessing**: Text cleaning, tokenization, feature engineering
- **Sentiment Analysis**: Multiple model approaches (traditional ML + deep learning)
- **Temporal Analysis**: Time series analysis with anomaly detection
- **Competitor Analysis**: Brand recognition and competitive intelligence
- **API Layer**: RESTful API for real-time analysis
- **Monitoring**: Prometheus metrics and Grafana dashboards

## üìä Results & Achievements

### üéØ Performance Metrics

Our MICAP platform has demonstrated exceptional performance across multiple dimensions:

#### **Deep Learning Model Performance**
- **LSTM Sentiment Classifier**: Achieved **75.4% accuracy** with **82.8% AUC**
- **Training Dataset**: 1.16M+ preprocessed records with balanced sentiment distribution
- **Processing Speed**: 270K+ samples processed efficiently with distributed computing
- **Model Architecture**: Advanced LSTM with 14 engineered numeric features + text embeddings

#### **Traditional ML Model Benchmarks**
Our comprehensive benchmarking across different data sizes reveals consistent performance:

| Model | Accuracy | F1-Score | Training Time | Prediction Time |
|-------|----------|----------|---------------|-----------------|
| **Random Forest** | **70.3%** | **70.3%** | 16.4s | 4.0s |
| **Gradient Boosting** | **69.9%** | **69.8%** | 9.7s | 0.9s |
| **Logistic Regression** | **68.5%** | **68.5%** | 1.8s | 0.8s |
| **Naive Bayes** | **67.2%** | **67.3%** | 2.5s | 2.0s |

*Results on 233K sample dataset (20% of full data)*

#### **Data Processing Achievements**
- **Scalability**: Successfully processed **1.44M records** in **626 seconds**
- **Language Detection**: 80.9% English content retention from multilingual dataset
- **Feature Engineering**: 26 engineered features + TF-IDF (1000 dims) + Word2Vec (100 dims)
- **Vocabulary Learning**: Word2Vec learned embeddings for 1,088+ high-frequency words

### üìà Market Intelligence Results

#### **Competitive Analysis Insights**
Our competitive intelligence platform provides comprehensive brand analysis:

```json
{
  "apple": {
    "market_position": "Leader",
    "share_of_voice": "36.9%",
    "total_mentions": "41,227",
    "sentiment_score": -21.0,
    "competitive_advantage": "Leading in mentions volume"
  }
}
```

#### **Advanced Analytics Capabilities**
- **Topic Modeling**: Automated discovery of 5 key market topics
- **Temporal Analysis**: Hourly sentiment trends with anomaly detection
- **Entity Recognition**: Brand and product identification with fuzzy matching
- **Competitive Positioning**: Multi-dimensional competitor comparison

### üé® Visualization Portfolio

Our platform generates comprehensive visualizations for business insights:

#### **Sentiment Analysis Visualizations**
- **Sentiment Heatmaps**: [`sentiment_heatmap.png`](data/visualizations/sentiment_heatmap.png)
- **Topic-based Sentiment**: [`sentiment_by_topic.png`](data/visualizations/sentiment_by_topic.png)
- **Temporal Patterns**: [`hourly_sentiment_trends.png`](data/visualizations/hourly_sentiment_trends.png)

#### **Market Intelligence Dashboards**
- **Competitive Positioning**: [`competitive_positioning.png`](data/phase2_results/visualizations/competitive_positioning.png)
- **Share of Voice Timeline**: [`share_of_voice_timeline.png`](data/phase2_results/visualizations/share_of_voice_timeline.png)
- **Sentiment Momentum**: [`sentiment_momentum.png`](data/phase2_results/visualizations/sentiment_momentum.png)

#### **Topic Analysis**
- **Topic Distribution**: [`topic_distribution.png`](data/visualizations/topic_distribution.png)
- **Word Clouds per Topic**: 5 generated topic-specific visualizations
- **Topic Sentiment Correlation**: [`topic_sentiment_heatmap.png`](data/visualizations/topic_sentiment_heatmap.png)

#### **Performance Benchmarks**
- **Model Comparison**: [`benchmark_plots.png`](data/models/benchmark_plots.png)
- **Scalability Analysis**: Training time vs data size across all models
- **Accuracy Trends**: Performance consistency across different dataset sizes

### üöÄ Technical Achievements

#### **Architecture Excellence**
- **Distributed Computing**: Apache Spark 4.0.0 with optimized memory allocation (8GB driver, 6GB executor)
- **MLOps Integration**: MLflow model tracking and versioning
- **Real-time Processing**: FastAPI backend with sub-second response times
- **Scalable Storage**: Parquet-based data lake with checkpoint system

#### **Code Quality Metrics**
- **Test Coverage**: 85%+ comprehensive testing suite
- **Documentation**: Complete API documentation with OpenAPI/Swagger
- **Performance**: Benchmark plots showing linear scalability
- **Monitoring**: Integrated Prometheus metrics and Grafana dashboards

#### **Business Impact Features**
- **Multi-model Ensemble**: 4 different ML algorithms for robust predictions
- **Feature Engineering**: 26 domain-specific features including sentiment lexicons
- **Temporal Intelligence**: Time-based pattern recognition and trend analysis
- **Competitive Intelligence**: Automated competitor monitoring and insights generation

### üìã Key Performance Indicators

| Metric | Achievement | Impact |
|--------|-------------|---------|
| **Data Processing Speed** | 1.16M records/10 mins | High-volume real-time analytics |
| **Model Accuracy** | 75.4% (LSTM) | Production-ready sentiment analysis |
| **Scalability** | Linear performance scaling | Enterprise-grade deployment ready |
| **Feature Coverage** | 1,126 engineered features | Comprehensive signal capture |
| **Language Support** | Multi-language detection | Global market analysis capability |
| **Visualization Suite** | 11+ automated charts | Executive-ready business insights |

### üéâ Notable Accomplishments

1. **Production-Ready Pipeline**: Complete end-to-end ML pipeline from raw data to business insights
2. **Advanced NLP**: Multi-model sentiment analysis with traditional and deep learning approaches
3. **Real-time Analytics**: Sub-second API response times for live sentiment analysis
4. **Competitive Intelligence**: Automated brand monitoring and competitor analysis
5. **Scalable Architecture**: Distributed computing with Apache Spark for enterprise workloads
6. **Comprehensive Testing**: 85%+ test coverage with unit, integration, and performance tests
7. **Business-Ready Visualizations**: Executive dashboard with actionable market insights

*All metrics based on latest pipeline execution (May 2025) with Sentiment140 dataset*

## üìä API Documentation

The API provides comprehensive endpoints for sentiment analysis and market intelligence:

### Endpoints

- `POST /analyze` - Analyze text sentiment
- `GET /trends/sentiment` - Get sentiment trends
- `GET /competitors/{brand}` - Competitor analysis
- `POST /batch/analyze` - Batch processing
- `GET /health` - Health check

### Interactive Documentation

When running the API, visit:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## üîß Development

### Setting Up Development Environment

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Setup pre-commit hooks
pre-commit install

# Run code formatting
black src/ tests/ scripts/
isort src/ tests/ scripts/

# Run linting
flake8 src/ tests/ scripts/
pylint src/
```

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test suites
pytest tests/unit/test_sentiment_models.py
pytest tests/integration/

# Run performance tests
python scripts/benchmark_performance.py
```

### Code Quality

The project enforces high code quality standards:

- **Black** for code formatting
- **isort** for import sorting
- **flake8** for linting
- **pylint** for advanced static analysis
- **mypy** for type checking
- **bandit** for security scanning

## üöÄ Deployment

### Docker Deployment

```bash
# Build production image
docker build --target production -t micap:latest .

# Run with docker-compose
docker-compose -f docker-compose.prod.yml up -d
```

### Kubernetes Deployment

```bash
# Apply Kubernetes manifests
kubectl apply -f k8s/

# Check deployment status
kubectl get pods -l app=micap
```

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `ENV` | Environment (dev/staging/prod) | `development` |
| `DATABASE_URL` | PostgreSQL connection string | - |
| `REDIS_URL` | Redis connection string | - |
| `SPARK_MASTER_URL` | Spark master URL | `local[*]` |

## üß™ Testing

The project includes comprehensive testing at multiple levels:

### Test Categories

- **Unit Tests**: Individual component testing
- **Integration Tests**: Cross-component testing
- **Performance Tests**: Benchmarking and load testing
- **End-to-End Tests**: Full pipeline testing

### Test Coverage

Current test coverage: **85%+**

```bash
# Generate coverage report
pytest --cov=src --cov-report=html
open htmlcov/index.html
```

## üìä Monitoring

### Metrics Collection

- **Application Metrics**: Request latency, throughput, error rates
- **ML Metrics**: Model accuracy, prediction confidence, drift detection
- **Infrastructure Metrics**: CPU, memory, disk usage
- **Business Metrics**: Sentiment trends, competitor insights

### Dashboards

Access monitoring dashboards:
- Grafana: http://localhost:3000 (admin/admin)
- Prometheus: http://localhost:9090
- Spark UI: http://localhost:8080

## ü§ù Contributing

We welcome contributions! Please read our [Contributing Guide](CONTRIBUTING.md) for details.

### Development Workflow

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes
4. Run tests and linting
5. Commit changes (`git commit -m 'Add amazing feature'`)
6. Push to branch (`git push origin feature/amazing-feature`)
7. Open a Pull Request

### Code Standards

- Follow PEP 8 style guidelines
- Write comprehensive docstrings
- Add tests for new functionality
- Update documentation as needed

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## üôè Acknowledgments

- Apache Spark community for distributed computing framework
- Hugging Face for transformer models
- spaCy for NLP processing
- TensorFlow and PyTorch teams for deep learning frameworks

## üìû Support

- **Issues**: [GitHub Issues](https://github.com/itsalivafaei/micap/issues)
- **Discussions**: [GitHub Discussions](https://github.com/itsalivafaei/micap/discussions)
- **Email**: beady_stats.38@icloud.com

---

**Built with ‚ù§Ô∏è**
